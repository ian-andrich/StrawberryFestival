# Orders of Business

1. Go through the news articles around the Q* and Strawberry Leaks to find the papers relating to the project, listed below.
2. Rank them by strength of effect, ease of implementation, ease of operationalizing, and raw dankness, etc. Attempt to categorize them into relevant buckets.
3. Write up code snippets so that people can treat them as templates.

# StrawberryFestival
An open source repository dedicated to compiling papers and code relating to Strawberry/Q*.

A [Very Rough Perplexity Page Describing It](https://www.perplexity.ai/page/q-leak-at-openai-overview-LmxxlXACT3m6ahnN6G1kLg)  
[AI Explained Video (Q* Explained)](https://www.youtube.com/watch?v=ARf0WyFau0A)

Start by dumping links to the research papers here:

### STaR -- Self TAught Reasoner
- **[The OG Quiet Star Paper](https://arxiv.org/abs/2403.09629)**

- **[Improvement on Quiet STaR?](https://contextual.ai/addressing-underspecification-in-language-model-alignment/)**

- **[Let's Verify Step by Step](https://arxiv.org/abs/2305.20050)**
  
  *Description*: This paper focuses on enhancing the reasoning process of AI models by verifying each step in a reasoning sequence, rather than just the final answer. It proposes a method to significantly improve the accuracy of AI-generated solutions by focusing on process validation.

- **[Attention is All You Need](https://arxiv.org/abs/1706.03762)**
  
  *Description*: This seminal paper introduces the Transformer model, which has become the foundation for many advanced AI models, including GPT. The paper explains how attention mechanisms can improve the efficiency and effectiveness of neural networks in processing sequences.

- **[GSM8K: A Dataset for Math Word Problems](https://arxiv.org/abs/2110.14168)**
  
  *Description*: The GSM8K dataset consists of 8,000 diverse and challenging grade-school-level math word problems. It is used to benchmark the performance of AI models in solving mathematical problems, particularly focusing on multi-step reasoning.

- **[Test-Time Computation](https://arxiv.org/abs/2104.03220)**
  
  *Description*: This paper explores the concept of test-time computation, where additional computational resources are used during the inference phase to generate multiple candidate solutions. The best solution is then selected using a verification model, improving overall accuracy.

- **[Prover Verifier Games for Legibility](https://openai.com/index/prover-verifier-games-improve-legibility/)**

### Original Attention is All You Need
- **[OG "Attention is All You Need" Paper](https://arxiv.org/pdf/1706.03762)**
